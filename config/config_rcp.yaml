# config/config.yaml

attacker:
  provider: "epfl_rcp"
  provider_key: "sk-_Z1xNaV9TzEto9Osul01Bg"
  model: "Qwen/Qwen3-Next-80B-A3B-Instruct"
  temperature: 0.5
  max_retries: 3            # only one attempt
  max_turns: 10              # single-turn adversarial attempt
  plan_revision: true           # whether to extend unsuccessful plans that ran out of phases
  run_all_strategies: false     # only require one successful strategy per behavior
  plans_file: "./strategies/2025-11-20_23-21-43/attack_plans.json"
  strategies_per_behavior: 5

target:
  provider: "epfl_rcp"
  provider_key: "sk-_Z1xNaV9TzEto9Osul01Bg"
  model: "Qwen/Qwen3-Next-80B-A3B-Instruct"
  temperature: 0
  max_retries: 3             # single attempt against target

textgrad:
  enabled: false
  provider: "ollama"          # was "openrouter"
  model: "qwen3:32b"     # any model the server hosts
  port: 11502                 # <— match your running server
  temperature: 0
  think: true
  max_retries: 10             # single optimization pass
  max_turns_per_phase: 4    # one gradient phase

attack_validation:
  max_tokens_for_evaluation: 512

multithreading:
  max_workers: 1

attack_plan_generator:
  provider: "epfl_rcp"
  provider_key: "sk-_Z1xNaV9TzEto9Osul01Bg"
  model: "Qwen/Qwen3-Next-80B-A3B-Instruct"
  temperature: 0.5
  max_retries: 3
  behavior_path: "./behaviors/harmbench_behaviors_text_test.csv"
  attack_plan_generation_dir: "./strategies"
  progress_dir: "./strategies/progress_new"
  num_behaviors: 176

generator:
  model_name : "google/gemma-3-12b-it"
  auth_token: "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"
  # Your Hugging Face token (can also be set as an environment variable)

evaluation:
  use_gpt_judge: true           # <— turn off GPT-only path
  judge_provider: "epfl_rcp"
  judge_provider_key: "sk-_Z1xNaV9TzEto9Osul01Bg"              # your judge server port
  judge_model: "Qwen/Qwen3-Next-80B-A3B-Instruct"
  require_llm_for_advance: true